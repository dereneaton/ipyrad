#!/usr/bin/env python

"""Fetch SNP site depth information for a single sample.

This uses information in the tmpdir/chunk-x-y.npy files which
contain shift-table information generated by ChunkProcessor for
DENOVO data containing info about the position of variable sites
in the consens calls after accounting for trimmed edges and 
alignment changes that have occurred after step5.

Input
-----
>>> lidx  sidx  cidx  pos  shift
>>>    0     0     0    0      0
>>>    0     1    22    0     -2
>>>    0     2    12    0     -2

Output for each sample
----------------------
>>> lidx   pos   depth   C   A   T   G
>>>    0    14      10   0   0   0  10
>>>    0    22      10   0   0   0  10
>>>    0    83      10   0  10   0   0
>>>    1     3      20   0   0  20   0
>>>   ...   # skips any loci and sites where this sample is missing.
>>>    3     x      

Eventual combined file
----------------------
>>> lidx   pos   depth   s1          s2          s3           s4  ...
>>>    0    14     350   9:0,0,0,9   0:0,0,0,0   10:0,0,0,10  ...

"""

from typing import List, Iterator, Tuple
from pathlib import Path
import numpy as np
import h5py

class New:
    def __init__(self, data: 'Assembly', sname: str):
        self.data = data
        self.sample = self.data.samples[sname]
        self.sidx = sorted(self.data.samples).index(sname)

    def _get_sorted_npys(self) -> List[Path]:
        """Gather all loci bits and sort by filename. And get snppad len."""
        return sorted(
            Path(self.data.tmpdir).glob("chunk-*.npy"),
            key=lambda x: int(x.name.split('-')[1]))

    def _get_catgs(self) -> np.ndarray:
        """..."""
        with h5py.File(self.sample.files.depths, 'r') as io5:
            return io5["catgs"][:]

    def _iter_loci(self) -> Iterator[np.ndarray]:
        """Yield each locus one at a time from full loaded array.
    
        The shift table arrays are chunked to be each pretty small
        so we can load each entire one in at a time without concern.

        >>> 0  0    0   4  0
        >>> 0  1   33   4  0
        >>> 0  2   22   4  1
        >>> 0  3  500   4  1
        >>> 0  0   32  10  0
        >>> 0  1  302  10  0   # yields locus 0
        >>> ...
        >>> 1  0  ...
        >>> ...                # yields locus 1
        """
        for npy in self._get_sorted_npys():
            arr = np.load(npy)
            lidxs = np.unique(arr[:, 0])
            for lidx in lidxs:
                yield arr[arr[:, 0] == lidx]

    def _iter_snvs(self) -> Iterator[Tuple[int, int, np.ndarray]]:
        """Yield a single variable site for samples w/ data.
        
        Note: this discard the raw locus ID (lidx) and replaces it
        with an enumeration of locus IDs ordered from 0-nloci in chunk.

        >>> 0  0    0   4  0
        >>> 0  1   33   4  0
        >>> 0  2   22   4  1
        >>> 0  3  500   4  1   # yields locus 0 site 4
        >>> 0  0   32  10  0
        >>> 0  1  302  10  0   # yields locus 0 site 10
        """
        for lidx, loc in enumerate(self._iter_loci()):
            for pos in np.unique(loc[:, 3]):
                yield lidx, pos, loc[loc[:, 3] == pos]

    def _iter_sample_depths(self) -> List[int]:
        """Yields a list with pos and depth info at all SNPs.

        >>> lidx   pos depth   C   A   T   G   # no actual header
        >>>   0     20    33  33   0   0   0
        >>>   0     88    33   0  33   0   0
        >>>   0    120    33  33   0   0   0
        >>> ...
        >>> 980     15    12   0   0  12   0        
        """
        depths = self._get_catgs()
        for lidx, pos, sloc in self._iter_snvs():
            # select only this sample at this locus for all sites
            srow = sloc[sloc[:, 1] == self.sidx]
            if not srow.size:
                yield lidx, pos, 0, 0, 0, 0, 0
            else:
                _, _, cidx, _, shift = srow[0]
                catg = depths[cidx][pos + shift]
                row = [lidx, pos, sum(catg)] + list(catg)
                yield row

    def run(self) -> np.ndarray:
        """Fetches all SNP depth info re-aligned and into an array."""
        return np.array(list(self._iter_sample_depths()))


class Combined:
    """

    Combined file format
    --------------------
    >>> lidx   pos   depth   s1          s2          s3           s4  ...
    >>>    0    14     350   9:0,0,0,9   0:0,0,0,0   10:0,0,0,10  ...

    """
    def __init__(self, data: 'Assembly', snpsmap: np.ndarray):
        self.data = data

    def _load_sample_depths(self):
        pass

    def _expand_sample_depths_for_missing(self):
        pass

    def combine_sample_depths(self):
        pass



if __name__ == "__main__":

    import ipyrad as ip

    DATA = ip.load_json("../../tests/ipsim.json")
    DATA.tmpdir = DATA.params.project_dir / "ipsim_tmp_outfiles"

    NEW = New(DATA, "1B_0")
    ARR = NEW.run()
    print(ARR)


    # DATA = ip.load_json("../../sra-fastqs/cyatho.json")
    # DATA.tmpdir = Path("../../sra-fastqs/cyatho_tmp_outfiles/")
    # SAMPLE = DATA.samples["29154_superba_
    # get_depths()


    # t = Spacer(DATA, DATA.samples)
    # t.run()
    # i = t._iter_loci()
    # print(next(i))


